"""
Ù…Ø¹Ø§Ù„Ø¬ ØªØ¶Ù…ÙŠÙ† Ø§Ù„Ø¢ÙŠØ§Øª (Vectors) - Ù†Ø³Ø®Ø© Production
===========================================
ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„Ø© Ø¹Ù† ØªÙˆÙ„ÙŠØ¯ ÙˆØ­ÙØ¸ ÙˆØªØ­Ù…ÙŠÙ„ Ù…ØªØ¬Ù‡Ø§Øª Ø§Ù„Ø¢ÙŠØ§Øª (Embeddings)

ğŸ”´ ØªÙ… ØªØ¹Ø·ÙŠÙ„ SentenceTransformer Ù„ØªÙˆÙÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø© (2.1 GB)
âœ… Ù†Ø³ØªØ®Ø¯Ù… ÙÙ‚Ø· Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© (24 MB) + FAISS Index (24 MB)

Ø§Ù„ØªØºÙŠÙŠØ±Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:
1. âŒ ØªØ¹Ø·ÙŠÙ„ model.encode() â†’ Ù„Ù† Ù†Ø­ØªØ§Ø¬ SentenceTransformer
2. âœ… ØªØ­Ù…ÙŠÙ„ embeddings Ø¬Ø§Ù‡Ø²Ø© ÙÙ‚Ø· Ù…Ù† quran_embeddings.npy
3. âœ… ØªØ­Ù…ÙŠÙ„ FAISS index Ù…Ù† quran_faiss_index.bin
4. âš ï¸ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ù…Ø¹Ø·Ù‘Ù„ Ù…Ø¤Ù‚ØªØ§Ù‹ (ÙŠØ­ØªØ§Ø¬ model.encode)
"""

import numpy as np
import faiss
import time
import os
import io
from typing import Tuple, List, Optional
from sqlalchemy.orm import Session
# ğŸ”´ ØªÙ… Ø¥Ø²Ø§Ù„Ø©: from sentence_transformers import SentenceTransformer

# Ù…Ù„ÙØ§Øª Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª (Ù…ÙˆØ¬ÙˆØ¯Ø© ÙˆÙ…Ø¨Ù†ÙŠØ© Ù…Ø³Ø¨Ù‚Ø§Ù‹)
EMBEDDINGS_FILE = "quran_embeddings.npy"       # 24 MB - Ù…ØªØ¬Ù‡Ø§Øª Ø¬Ø§Ù‡Ø²Ø©
FAISS_INDEX_FILE = "quran_faiss_index.bin"    # 24 MB - ÙÙ‡Ø±Ø³ FAISS
QURAN_IDS_FILE = "quran_ids.npy"              # ØµØºÙŠØ± Ø¬Ø¯Ø§Ù‹

# ğŸ”´ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ù…Ø¹Ø·Ù‘Ù„ ÙÙŠ Production
# EMBEDDING_MODEL_NAME = "intfloat/multilingual-e5-large"  # 2.1 GB
PRODUCTION_MODE = True  # ÙˆØ¶Ø¹ Production - Ø¨Ø¯ÙˆÙ† Model

# ===========================================
# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ù…ØªØ£Ø®Ø± Ù„ØªØ¬Ù†Ø¨ Ø§Ù„Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§Ù„Ø¯ÙˆØ±ÙŠ
# ===========================================
def get_verse_model(db: Session):
    """Ø¬Ù„Ø¨ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø¢ÙŠØ© Ù…Ù† database.py"""
    from database import Verse 
    return Verse

# ===========================================
# ğŸ”´ ØªÙ… ØªØ¹Ø·ÙŠÙ„: ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª (Ù„Ù† Ù†Ø­ØªØ§Ø¬Ù‡Ø§ ÙÙŠ Production)
# ===========================================

def generate_embeddings(db: Session, model=None) -> Tuple[np.ndarray, np.ndarray]:
    """
    âŒ Ù…Ø¹Ø·Ù‘Ù„ ÙÙŠ Production Mode
    
    Ø§Ù„Ø³Ø¨Ø¨: ÙŠØ­ØªØ§Ø¬ SentenceTransformer (2.1 GB)
    Ø§Ù„Ø¨Ø¯ÙŠÙ„: Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© ÙÙŠ quran_embeddings.npy
    """
    if PRODUCTION_MODE:
        print("âš ï¸ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª Ù…Ø¹Ø·Ù‘Ù„ ÙÙŠ Production Mode")
        print("âœ… Ø³Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© Ù…Ù† quran_embeddings.npy")
        return np.array([]), np.array([])
    
    # Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ… (Ù„Ù† ÙŠØ¹Ù…Ù„ ÙÙŠ Production)
    # ...

# ===========================================
# âœ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† Model)
# ===========================================

def load_or_generate_embeddings(db: Session) -> Tuple[np.ndarray, np.ndarray, faiss.IndexFlatL2, None]:
    """
    ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³ ÙˆØ§Ù„Ù…ØªØ¬Ù‡Ø§Øª Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© Ù…Ù† Ø§Ù„Ù…Ù„ÙØ§Øª
    
    ğŸ”´ Ø§Ù„ØªØºÙŠÙŠØ±: Ù„Ù† Ù†Ø­Ù…Ù‘Ù„ SentenceTransformer (ØªÙˆÙÙŠØ± 2.1 GB)
    âœ… Ø§Ù„Ù†ØªÙŠØ¬Ø©: startup Ø³Ø±ÙŠØ¹ (2-3 Ø«ÙˆØ§Ù†ÙŠ) Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† (30-45 Ø«Ø§Ù†ÙŠØ©)
    
    Returns:
        embeddings: np.ndarray - Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© (24 MB)
        verse_ids: np.ndarray - Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ø¢ÙŠØ§Øª
        faiss_index: faiss.IndexFlatL2 - Ø§Ù„ÙÙ‡Ø±Ø³ Ø§Ù„Ø¬Ø§Ù‡Ø² (24 MB)
        model: None - âŒ Ù…Ø¹Ø·Ù‘Ù„ ÙÙŠ Production
    """
    embeddings = None
    verse_ids = None
    faiss_index = None
    
    Verse = get_verse_model(db)
    
    # ğŸ”´ ØªÙ… Ø¥Ø²Ø§Ù„Ø©: ØªØ­Ù…ÙŠÙ„ SentenceTransformer
    print("ğŸš€ Production Mode: ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© ÙÙ‚Ø· (Ø¨Ø¯ÙˆÙ† Model)")
    model = None  # Ù„Ù† Ù†Ø­Ù…Ù‘Ù„ Model ÙÙŠ Production
    
    # âœ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø§Ù‡Ø²Ø©
    if os.path.exists(FAISS_INDEX_FILE) and os.path.exists(QURAN_IDS_FILE) and os.path.exists(EMBEDDINGS_FILE):
        try:
            print(f"ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª Ù…Ù† {EMBEDDINGS_FILE}...")
            embeddings = np.load(EMBEDDINGS_FILE)
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª. Ø§Ù„Ø´ÙƒÙ„: {embeddings.shape}")
            
            print(f"ğŸ”„ Ø¬Ø§Ø±ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³ Ù…Ù† {FAISS_INDEX_FILE}...")
            faiss_index = faiss.read_index(FAISS_INDEX_FILE)
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„ÙÙ‡Ø±Ø³ Ø¨Ù†Ø¬Ø§Ø­. Ø¹Ø¯Ø¯ Ø§Ù„Ø¹Ù†Ø§ØµØ±: {faiss_index.ntotal}")
            
            verse_ids = np.load(QURAN_IDS_FILE)
            print(f"âœ… ØªÙ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª. Ø§Ù„Ø¹Ø¯Ø¯: {len(verse_ids)}")
            
            print("=" * 50)
            print("âœ… Ø§Ù„Ù†Ø¸Ø§Ù… Ø¬Ø§Ù‡Ø²! (Ø¨Ø¯ÙˆÙ† Model - ØªÙˆÙÙŠØ± 2.1 GB)")
            print("=" * 50)
            
            return embeddings, verse_ids, faiss_index, model
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ­Ù…ÙŠÙ„ Ù…Ù„ÙØ§Øª Ø§Ù„ÙÙ‡Ø±Ø³: {e}")
            print("âš ï¸ ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:")
            print(f"   - {EMBEDDINGS_FILE}")
            print(f"   - {FAISS_INDEX_FILE}")
            print(f"   - {QURAN_IDS_FILE}")
            return np.array([]).astype('float32'), np.array([]), None, model
    else:
        print("âŒ Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø¬Ø§Ù‡Ø²Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©!")
        print("âš ï¸ ÙŠØ¬Ø¨ ØªÙˆÙÙŠØ± Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„ØªØ§Ù„ÙŠØ©:")
        print(f"   - {EMBEDDINGS_FILE} (Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª)")
        print(f"   - {FAISS_INDEX_FILE} (Ø§Ù„ÙÙ‡Ø±Ø³)")
        print(f"   - {QURAN_IDS_FILE} (Ø§Ù„Ù…Ø¹Ø±ÙØ§Øª)")
        return np.array([]).astype('float32'), np.array([]), None, model

# ===========================================
# âš ï¸ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ - Ù…Ø¹Ø·Ù‘Ù„ Ù…Ø¤Ù‚ØªØ§Ù‹
# ===========================================

def search_similar_verses_faiss(
    query_text: str,
    limit: int,
    faiss_index: faiss.IndexFlatL2,
    embedding_model,  # ğŸ”´ Ø³ÙŠÙƒÙˆÙ† None ÙÙŠ Production
    verse_ids: np.ndarray,
    db: Session,
    threshold: float = 0.4
) -> List[dict]:
    """
    Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ÙÙ‡Ø±Ø³ Ø¹Ù† Ø¢ÙŠØ§Øª Ù…ØªØ´Ø§Ø¨Ù‡Ø© Ø¯Ù„Ø§Ù„ÙŠØ§Ù‹
    
    âš ï¸ Ù…Ø¹Ø·Ù‘Ù„ ÙÙŠ Production Mode Ù„Ø£Ù†Ù‡ ÙŠØ­ØªØ§Ø¬ model.encode()
    
    Ø§Ù„Ø¨Ø¯ÙŠÙ„ Ø§Ù„Ù…ØªØ§Ø­:
    - âœ… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù†ØµÙŠ Ø§Ù„Ø¹Ø§Ø¯ÙŠ (ÙŠØ¹Ù…Ù„ 100%)
    - âœ… Ø§Ù„Ø¨Ø­Ø« Ø¨Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ÙŠØ© (ÙŠØ¹Ù…Ù„ 100%)
    - âœ… Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª ÙˆØ§Ù„Ø£Ø³Ø¦Ù„Ø© (ØªØ¹Ù…Ù„ 100%)
    
    Ù…Ù„Ø§Ø­Ø¸Ø©: ÙŠÙ…ÙƒÙ† ØªÙØ¹ÙŠÙ„ Ù‡Ø°Ù‡ Ø§Ù„Ù…ÙŠØ²Ø© Ù„Ø§Ø­Ù‚Ø§Ù‹ Ø¹Ù†Ø¯ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø®Ø¯Ù…Ø© Ø£ÙƒØ¨Ø±
    """
    Verse = get_verse_model(db)
    
    # ğŸ”´ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Model (Ù„Ù† ÙŠÙƒÙˆÙ† Ù…ÙˆØ¬ÙˆØ¯Ø§Ù‹)
    if embedding_model is None:
        print("âš ï¸ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ Ù…Ø¹Ø·Ù‘Ù„ ÙÙŠ Production Mode")
        print("âœ… Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù†ØµÙŠ Ø§Ù„Ø¹Ø§Ø¯ÙŠ Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù†Ù‡")
        return []
    
    # ğŸ”´ Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ù„ÙÙ‡Ø±Ø³
    if faiss_index is None or verse_ids.size == 0:
        print("âŒ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø« ØºÙŠØ± Ù…Ù‡ÙŠØ£.")
        return []
        
    # ğŸ”´ Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„ØªØ§Ù„ÙŠ Ù„Ù† ÙŠØ¹Ù…Ù„ Ø¨Ø¯ÙˆÙ† Model
    # Ù„Ø£Ù† model.encode() ØªØ­ØªØ§Ø¬ SentenceTransformer
    
    """
    # Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù‚Ø¯ÙŠÙ… (Ù…Ø¹Ø·Ù‘Ù„):
    start_time = time.time()
    
    # 1. ØªÙˆÙ„ÙŠØ¯ Ù…ØªØ¬Ù‡ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙØ¯Ø®Ù„ (ÙŠØ­ØªØ§Ø¬ Model!)
    query_embedding = embedding_model.encode(
        [query_text], 
        convert_to_numpy=True, 
        normalize_embeddings=True
    )[0]
    query_embedding = np.expand_dims(query_embedding, axis=0).astype('float32')
    
    # 2. Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ÙÙ‡Ø±Ø³
    k = limit + 1
    D, I = faiss_index.search(query_embedding, k)
    
    # ... Ø¨Ø§Ù‚ÙŠ Ø§Ù„ÙƒÙˆØ¯
    """
    
    print("âš ï¸ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ ÙŠØ­ØªØ§Ø¬ SentenceTransformer (Ù…Ø¹Ø·Ù‘Ù„ ÙÙŠ Production)")
    return []


# ===========================================
# âœ… Ø¯Ø§Ù„Ø© Ù…Ø³Ø§Ø¹Ø¯Ø©: Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ embedding Ø¬Ø§Ù‡Ø² Ø­Ø³Ø¨ index
# ===========================================

def get_embedding_by_verse_id(
    verse_id: int,
    embeddings: np.ndarray,
    verse_ids: np.ndarray
) -> Optional[np.ndarray]:
    """
    Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù…ØªØ¬Ù‡ Ø¬Ø§Ù‡Ø² Ù„Ø¢ÙŠØ© Ù…Ø¹ÙŠÙ†Ø©
    
    âœ… ÙŠØ¹Ù…Ù„ Ø¨Ø¯ÙˆÙ† Model (Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØªØ¬Ù‡Ø§Øª Ø§Ù„Ø¬Ø§Ù‡Ø²Ø©)
    
    Ù…ÙÙŠØ¯ Ù„Ù€:
    - Ù…Ù‚Ø§Ø±Ù†Ø© Ø§Ù„Ø¢ÙŠØ§Øª
    - Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
    - Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¥Ø­ØµØ§Ø¦ÙŠØ©
    """
    try:
        # Ø¥ÙŠØ¬Ø§Ø¯ Ù…ÙˆÙ‚Ø¹ Ø§Ù„Ø¢ÙŠØ© ÙÙŠ Ø§Ù„Ù…ØµÙÙˆÙØ©
        index = np.where(verse_ids == verse_id)[0]
        
        if len(index) > 0:
            return embeddings[index[0]]
        else:
            print(f"âš ï¸ Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø§Ù„Ø¢ÙŠØ© {verse_id}")
            return None
            
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ get_embedding_by_verse_id: {e}")
        return None


# ===========================================
# âœ… Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù…
# ===========================================

def get_system_info(
    embeddings: np.ndarray,
    faiss_index: faiss.IndexFlatL2,
    model
) -> dict:
    """
    Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø­Ø§Ù„Ø© Ø§Ù„Ù†Ø¸Ø§Ù…
    
    Ù…ÙÙŠØ¯ Ù„Ù€:
    - Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„ÙØ§Øª
    - Ù…Ø¹Ø±ÙØ© Ø§Ø³ØªÙ‡Ù„Ø§Ùƒ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
    - Debugging
    """
    return {
        'production_mode': PRODUCTION_MODE,
        'model_loaded': model is not None,
        'embeddings_loaded': embeddings is not None and embeddings.size > 0,
        'faiss_index_loaded': faiss_index is not None,
        'total_verses': len(embeddings) if embeddings is not None else 0,
        'embedding_dimension': embeddings.shape[1] if embeddings is not None and len(embeddings.shape) > 1 else 0,
        'memory_saved_gb': 2.1,  # ØªÙ… ØªÙˆÙÙŠØ± 2.1 GB
        'features_available': {
            'text_search': True,          # âœ… ÙŠØ¹Ù…Ù„
            'semantic_search': False,     # âŒ Ù…Ø¹Ø·Ù‘Ù„
            'statistics': True,           # âœ… ÙŠØ¹Ù…Ù„
            'approved_questions': True,   # âœ… ÙŠØ¹Ù…Ù„
            'verse_retrieval': True,      # âœ… ÙŠØ¹Ù…Ù„
        }
    }